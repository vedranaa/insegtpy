{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d05cc7b",
   "metadata": {},
   "source": [
    "# Interactively segmenting fibers\n",
    "InSegt-py is a py version of [InSegt](https://github.com/vedranaa/InSegt). Basic variant of InSegt is described in our paper [Content-based Propagation of User Markings for Interactive Segmentation of Patterned Images](http://openaccess.thecvf.com/content_CVPRW_2020/papers/w57/Dahl_Content-Based_Propagation_of_User_Markings_for_Interactive_Segmentation_of_Patterned_CVPRW_2020_paper.pdf), CVPRW 2020. But InSegt has evolved, so please check the demos and notebooks for the updated version.\n",
    "\n",
    "This is an example of interactive image segmentation with InSegt. Here we usa a model which builds dictionay by clustering image features in a k-means tree. For features we use Gaussian derivatives, where we use a few different values for the standard deviation of the Gaussian kernel. Furthermore, the model is made multi-scale by building and including sub-models operating on a downscaled version of the input image. \n",
    "\n",
    "In this example, we use a sub-volume of a fiber composite material. The study of the data is described in the article [Individual fibre inclination segmentation from X-ray computed tomography using principal component analysis](https://journals.sagepub.com/doi/epub/10.1177/00219983211052741), Journal of Composite Materials 2021. The data is available from [Zenodo](https://zenodo.org/records/5483719).\n",
    "\n",
    "## Import packages\n",
    "Most importantly, you need `insegt` and `insegtpy.models`. You also need to be able to read in the image (for example using `PIL`), and show the result (for example using `matplotlib`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081e817-3ef5-441e-8ec9-81a4af15646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules needed \n",
    "import insegtpy\n",
    "import insegtpy.models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tifffile\n",
    "import urllib.request \n",
    "import skimage.filters\n",
    "import skimage.feature\n",
    "import PIL.Image\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce70050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Load image from tiff repository - choose between 'Mock' and 'UD'\n",
    "\n",
    "name = 'UD' # 'Mock' or 'UD'\n",
    "vol_name = {'Mock': 'Mock_cropped.tif', 'UD': 'UD_cropped.tif'}\n",
    "\n",
    "url_in = 'https://data.qim.dk/InSegt_data/3D/' + vol_name[name] \n",
    "urllib.request.urlretrieve(url_in, 'Volume.tif')\n",
    "V = tifffile.imread('Volume.tif')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(V[100], cmap='gray')\n",
    "ax[0].set_title('XY plane')\n",
    "ax[1].imshow(V[:,100], cmap='gray')\n",
    "ax[1].set_title('XZ plane')\n",
    "ax[2].imshow(V[:,:,100], cmap='gray')\n",
    "ax[2].set_title('YZ plane')\n",
    "plt.show()\n",
    "\n",
    "dir_out = 'model/' # Output directory - potentially change this to your own directory\n",
    "if not os.path.exists(dir_out):\n",
    "    os.makedirs(dir_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba98152-1436-444b-9f2c-c2b983c81a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Build the model - only possible to build a small model from such a small image\n",
    "image_train = V[100]\n",
    "model = insegtpy.models.gauss_features_segmentor(image_train, \n",
    "                                   branching_factor = 5, \n",
    "                                   number_layers = 5,\n",
    "                                   number_training_vectors = 20000,\n",
    "                                   features_sigma = [1, 2],\n",
    "                                   propagation_size = 9, \n",
    "                                   scales=[1, 0.75],\n",
    "                                   propagation_repetitions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the annotation GUI\n",
    "ex = insegtpy.insegt(image_train, model, saveAddress=dir_out, savePrefix=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ac884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show probabilities of segmentation\n",
    "\n",
    "ncls = ex.probabilities.shape[0]\n",
    "fig, ax = plt.subplots(1,ncls)\n",
    "for i in range(ncls):\n",
    "    ax[i].imshow(ex.probabilities[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61739d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare segmentation of training and test image\n",
    "\n",
    "prob = ex.probabilities\n",
    "seg = insegtpy.utils.segment_probabilities(prob)\n",
    "\n",
    "# Another slide\n",
    "image_test = V[0]\n",
    "\n",
    "prob_new = model.segment_new(image_test)\n",
    "seg_new = insegtpy.utils.segment_probabilities(prob_new)\n",
    "seg_new[seg_new==0] = 1 # if some pixels are set to zero\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, sharex = True, sharey = True )\n",
    "ax[0][0].imshow(image_train)\n",
    "ax[1][0].imshow(seg)\n",
    "ax[1][0].set_title('Train')\n",
    "ax[0][1].imshow(image_test)\n",
    "ax[1][1].imshow(seg_new)\n",
    "ax[1][1].set_title('Test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to file\n",
    "model_file_name = 'segmentation_model_ud.pkl'\n",
    "with open(os.path.join(dir_out, model_file_name), 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365da013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment all files in a repository\n",
    "V_prob = []\n",
    "V_seg = []\n",
    "\n",
    "for im in V:\n",
    "    prob = model.segment_new(im)\n",
    "    seg = insegtpy.utils.segment_probabilities(prob)\n",
    "    seg[seg==0] = 1\n",
    "    V_prob.append(prob[2])\n",
    "    V_seg.append(seg)\n",
    "V_prob = np.array(V_prob)\n",
    "V_seg = np.array(V_seg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63deace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot center points of the segmented fibers\n",
    "\n",
    "pts = []\n",
    "for i, porb in enumerate(V_prob):\n",
    "    prob = skimage.filters.gaussian(porb, 2)\n",
    "    coords = skimage.feature.peak_local_max(prob, min_distance=5, threshold_abs=0.1)\n",
    "    pts.append(np.append(coords-1, i*np.ones((coords.shape[0],1)), axis=1))\n",
    "pts = np.vstack(pts)\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(pts[:,0], pts[:,1], pts[:,2], 'b.', alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d834312",
   "metadata": {},
   "source": [
    "## Load saved model \n",
    "Assumes that the volume has been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222bd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from file\n",
    "model_file_name = 'segmentation_model_ud.pkl'\n",
    "with open(os.path.join(dir_out, model_file_name), 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "V_prob = []\n",
    "V_seg = []\n",
    "\n",
    "for im in V:\n",
    "    prob = model.segment_new(im)\n",
    "    seg = insegtpy.utils.segment_probabilities(prob)\n",
    "    seg[seg==0] = 1\n",
    "    V_prob.append(prob[2])\n",
    "    V_seg.append(seg)\n",
    "V_prob = np.array(V_prob)\n",
    "V_seg = np.array(V_seg)\n",
    "\n",
    "# Plot center points of the segmented fibers\n",
    "\n",
    "pts = []\n",
    "for i, porb in enumerate(V_prob):\n",
    "    prob = skimage.filters.gaussian(porb, 2)\n",
    "    coords = skimage.feature.peak_local_max(prob, min_distance=5, threshold_abs=0.1)\n",
    "    pts.append(np.append(coords-1, i*np.ones((coords.shape[0],1)), axis=1))\n",
    "pts = np.vstack(pts)\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(pts[:,0], pts[:,1], pts[:,2], 'b.', alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the annotation GUI with pre-annotated labels\n",
    "image_train = V[100]\n",
    "labels = np.array(PIL.Image.open(dir_out + name + '_annotations_index.png'))\n",
    "ex = insegtpy.insegt(image_train, model, saveAddress=dir_out, labels=labels, savePrefix=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d9585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insegtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
